{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4., 9.])\n",
      "tensor([1., 4., 9.])\n",
      "tensor([1., 4., 9.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.square(a))\n",
    "print(a**2)\n",
    "print(a * a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "\n",
    "def measure_square(func: tp.Callable, input: torch.Tensor):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    for _ in range(5):\n",
    "        func(input)\n",
    "\n",
    "    start.record()\n",
    "    func(input)\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return start.elapsed_time(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(size=(10000, 10000)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4678399562835693"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_square(torch.square, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4770560264587402"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_as_multiply(a: torch.Tensor):\n",
    "    return a * a\n",
    "\n",
    "\n",
    "measure_square(square_as_multiply, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4688639640808105"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_as_tensor(a: torch.Tensor):\n",
    "    return a**2\n",
    "\n",
    "\n",
    "measure_square(square_as_tensor, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "             aten::square        19.16%       1.032ms        51.99%       2.800ms       2.800ms       1.035ms        19.76%       5.239ms       5.239ms             1  \n",
      "                aten::pow        31.25%       1.683ms        32.51%       1.751ms       1.751ms       4.174ms        79.67%       4.204ms       4.204ms             1  \n",
      "        aten::result_type         0.07%       4.000us         0.07%       4.000us       4.000us      16.000us         0.31%      16.000us      16.000us             1  \n",
      "                 aten::to         0.04%       2.000us         0.04%       2.000us       2.000us      14.000us         0.27%      14.000us      14.000us             1  \n",
      "          cudaEventRecord         6.81%     367.000us         6.81%     367.000us      45.875us       0.000us         0.00%       0.000us       0.000us             8  \n",
      "         cudaLaunchKernel         0.78%      42.000us         0.78%      42.000us      42.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    cudaDeviceSynchronize        41.89%       2.256ms        41.89%       2.256ms       2.256ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.386ms\n",
      "Self CUDA time total: 5.239ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-19 22:06:51 4172098:4172098 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-19 22:06:51 4172098:4172098 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-19 22:06:51 4172098:4172098 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    torch.square(b)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::mul         0.90%     144.000us         1.09%     174.000us     174.000us       2.648ms       100.00%       2.648ms       2.648ms             1  \n",
      "          cudaEventRecord        84.02%      13.459ms        84.02%      13.459ms       6.729ms       0.000us         0.00%       0.000us       0.000us             2  \n",
      "         cudaLaunchKernel         0.19%      30.000us         0.19%      30.000us      30.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    cudaDeviceSynchronize        14.89%       2.385ms        14.89%       2.385ms       2.385ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 16.018ms\n",
      "Self CUDA time total: 2.648ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-19 22:07:18 4172098:4172098 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-19 22:07:18 4172098:4172098 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-19 22:07:18 4172098:4172098 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    square_as_multiply(b)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::pow        10.99%      83.000us        17.48%     132.000us     132.000us       1.462ms        99.25%       1.473ms       1.473ms             1  \n",
      "        aten::result_type         0.40%       3.000us         0.40%       3.000us       3.000us       7.000us         0.48%       7.000us       7.000us             1  \n",
      "                 aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.27%       4.000us       4.000us             1  \n",
      "          cudaEventRecord         2.78%      21.000us         2.78%      21.000us       3.500us       0.000us         0.00%       0.000us       0.000us             6  \n",
      "         cudaLaunchKernel         5.30%      40.000us         5.30%      40.000us      40.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    cudaDeviceSynchronize        80.53%     608.000us        80.53%     608.000us     608.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 755.000us\n",
      "Self CUDA time total: 1.473ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-19 22:07:20 4172098:4172098 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-19 22:07:20 4172098:4172098 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-19 22:07:20 4172098:4172098 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    square_as_tensor(b)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-mode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
