{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)\n",
    "input_image = np.random.randn(3, 3).astype(np.float32)\n",
    "kernel = np.random.randn(2, 2).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7031873 , -0.49028236, -0.32181433],\n",
       "       [-1.7550787 ,  0.20666447, -2.0112646 ],\n",
       "       [-0.5572507 ,  0.337217  ,  1.548836  ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3707366 ,  1.4252914 ],\n",
       "       [-0.27946392, -0.5596279 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_tensor = torch.tensor(np.expand_dims(np.expand_dims(input_image, 0), 0), dtype=torch.float32)\n",
    "kernel_tensor = torch.tensor(np.expand_dims(np.expand_dims(kernel, 0), 0), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6399,  1.2812],\n",
       "          [ 2.6673, -4.1109]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.conv2d(input_image_tensor, kernel_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7031873 , -0.49028236, -0.32181433,  0.        ],\n",
       "       [-1.7550787 ,  0.20666447, -2.0112646 ,  0.        ],\n",
       "       [-0.5572507 ,  0.337217  ,  1.548836  ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.pad(input_image, ((0, 1), (0, 1)))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1230462"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a[-2:, -2:] * kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6xtf_2nj3nbd6vgp9xc3gmwr0000gn/T/ipykernel_97253/1578809238.py:1: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1009.)\n",
      "  F.conv2d(input_image_tensor, kernel_tensor, padding=\"same\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6399,  1.2812,  1.0032],\n",
       "          [ 2.6673, -4.1109,  2.3241],\n",
       "          [ 1.2445,  1.7453, -2.1230]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.conv2d(input_image_tensor, kernel_tensor, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63991527,  1.28117325,  1.00319855],\n",
       "       [ 2.66732309, -4.11093248,  2.32407017],\n",
       "       [ 1.2444764 ,  1.74530696, -2.12304618]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(input_image, kernel, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing as tp\n",
    "\n",
    "\n",
    "def dilate(\n",
    "    kernel,\n",
    "    dilation: tp.Optional[tp.Union[int, tp.Tuple[int, int]]] = None,\n",
    "):\n",
    "    if not dilation:\n",
    "        dilation_height = dilation_weight = 1\n",
    "    elif isinstance(dilation, int):\n",
    "        dilation_height = dilation_weight = dilation\n",
    "    else:\n",
    "        assert len(dilation) == 2\n",
    "        dilation_height, dilation_weight = dilation\n",
    "\n",
    "    kernel_height, kernel_weight = kernel.shape\n",
    "    dilated_kernel = np.zeros(\n",
    "        (\n",
    "            kernel_height + (dilation_height - 1) * (kernel_height - 1),\n",
    "            kernel_weight + (dilation_weight - 1) * (kernel_weight - 1),\n",
    "        )\n",
    "    )\n",
    "    for i in range(0, kernel_height):\n",
    "        for j in range(0, kernel_weight):\n",
    "            dilated_kernel[i * dilation_height, j * dilation_weight] = kernel[i, j]\n",
    "\n",
    "    return dilated_kernel\n",
    "\n",
    "\n",
    "def conv2d(\n",
    "    input,\n",
    "    kernel,\n",
    "    stride: tp.Optional[tp.Union[int, tp.Tuple[int, int]]] = None,\n",
    "    padding: tp.Optional[tp.Union[int, tp.Tuple[int, int], str]] = None,\n",
    "    dilation: tp.Optional[tp.Union[int, tp.Tuple[int, int]]] = None,\n",
    "):\n",
    "    assert len(input.shape) == 2\n",
    "    assert len(kernel.shape) == 2\n",
    "\n",
    "    # Stride\n",
    "    if not stride:\n",
    "        stride_height = stride_weight = 1\n",
    "    elif isinstance(stride, int):\n",
    "        stride_height = stride_weight = stride\n",
    "    else:\n",
    "        assert len(stride) == 2\n",
    "        stride_height, stride_weight = stride\n",
    "\n",
    "    kernel = dilate(kernel, dilation)\n",
    "\n",
    "    # Pad input\n",
    "    # Use 4 parameters for padding to deal with imbalanced cases.\n",
    "    kernel_height, kernel_weight = kernel.shape\n",
    "\n",
    "    if not padding:\n",
    "        padding_up = padding_down = padding_left = padding_right = 0\n",
    "    elif isinstance(padding, str):\n",
    "        if padding == \"valid\":\n",
    "            padding_up = padding_down = padding_left = padding_right = 0\n",
    "        elif padding == \"same\":\n",
    "            assert stride_height == 1 and stride_weight == 1, \"'same' padding can only be applied to stride == 1.\"\n",
    "            # new_input_height == input_height + 2 * pad\n",
    "            # output_height = new_input_height - kernel_height + 1\n",
    "            # We want output_height == input_height\n",
    "            # Thus, new_input_height - kernel_height + 1 == new_input_height - 2 * pad\n",
    "            # 2 * pad == kernel_height - 1, w.r.t pad is integer.\n",
    "            # In case of imbalance, we pad more in 'down' and 'right'.\n",
    "            padding_up = int(np.floor((kernel_height - 1) / 2))\n",
    "            padding_down = int(np.ceil((kernel_height - 1) / 2))\n",
    "            padding_left = int(np.floor((kernel_weight - 1) / 2))\n",
    "            padding_right = int(np.ceil((kernel_weight - 1) / 2))\n",
    "\n",
    "        elif padding == \"full\":\n",
    "            padding_up = padding_down = kernel_height - 1\n",
    "            padding_left = padding_right = kernel_weight - 1\n",
    "        else:\n",
    "            raise Exception(f\"{padding} is not recognized. Can only be 'valid' or 'same' or 'full'.\")\n",
    "\n",
    "    elif isinstance(padding, int):\n",
    "        padding_up = padding_down = padding_left = padding_right = padding\n",
    "    else:\n",
    "        assert len(padding) == 2\n",
    "        padding_up = padding_down = padding[0]\n",
    "        padding_left = padding_right = padding[1]\n",
    "\n",
    "    input = np.pad(\n",
    "        input, ((padding_up, padding_down), (padding_left, padding_right)), mode=\"constant\", constant_values=(0, 0)\n",
    "    )\n",
    "    input_height, input_weight = input.shape\n",
    "\n",
    "    output_height = int(np.floor((input_height - kernel_height) / stride_height)) + 1\n",
    "    output_weight = int(np.floor((input_weight - kernel_weight) / stride_weight)) + 1\n",
    "    output = np.zeros((output_height, output_weight))\n",
    "\n",
    "    for i in range(0, output_height):\n",
    "        for j in range(0, output_weight):\n",
    "            row = i * stride_height\n",
    "            col = j * stride_weight\n",
    "            output[i, j] = np.sum(input[row : row + kernel_height, col : col + kernel_weight] * kernel)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8668,  0.1557, -0.0942],\n",
       "          [-0.4587,  0.9639,  0.6720],\n",
       "          [-2.8666,  2.4058, -0.2833]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.conv2d(input_image_tensor, kernel_tensor, padding=\"same\", dilation=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.86677182,  0.15573146, -0.09423998],\n",
       "       [-0.4586792 ,  0.96388455,  0.67204797],\n",
       "       [-2.86663812,  2.40575057, -0.28328256]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(input_image, kernel, padding=\"same\", dilation=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karpathy-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
