{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "a = np.random.rand(5)\n",
    "\n",
    "\n",
    "def online_softmax(x):\n",
    "    prev_max = float(\"-inf\")\n",
    "    curr_max = float(\"-inf\")\n",
    "    curr_exp_sum = 0.0\n",
    "    for elem in x:\n",
    "        prev_max = curr_max\n",
    "        curr_max = max(curr_max, elem)\n",
    "        curr_exp_sum = curr_exp_sum * math.exp(prev_max - curr_max) + math.exp(elem - curr_max)\n",
    "\n",
    "    return np.exp(x - curr_max) / curr_exp_sum\n",
    "\n",
    "\n",
    "np.allclose(online_softmax(a), np.exp(a) / np.sum(np.exp(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415, -0.1382643 ,  0.64768854,  1.52302986, -0.23415337],\n",
       "       [-0.23413696,  1.57921282,  0.76743473, -0.46947439,  0.54256004]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "a = np.random.randn(2, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16763982, 0.08884021, 0.19495956, 0.46784333, 0.08071708],\n",
       "       [0.07801474, 0.47830449, 0.21239961, 0.06165537, 0.16962579]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(a) / np.sum(np.exp(a), axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16763982, 0.08884021, 0.19495956, 0.46784333, 0.08071708],\n",
       "       [0.07801474, 0.47830449, 0.21239961, 0.06165537, 0.16962579]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(a - np.max(a, axis=-1, keepdims=True)) / np.sum(\n",
    "    np.exp(a - np.max(a, axis=-1, keepdims=True)), axis=-1, keepdims=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1676, 0.0888, 0.1950, 0.4678, 0.0807],\n",
       "        [0.0780, 0.4783, 0.2124, 0.0617, 0.1696]], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "F.softmax(torch.tensor(a), dim=-1)\n",
    "# np.allclose(online_softmax(a), F.softmax(torch.tensor(a), dim=-1).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karpathy-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
