{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Dataset` used to provide finite number of samples. By default each sample will be fetched no more than once.\n",
    "- `IterableDataset` is used when the number of samples are to be decided. Samples can repeat."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `for-loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: tensor([-2.0260, -2.0655, -1.2054, -0.9122, -1.2502,  0.8032, -0.2071,  0.0544,\n",
      "         0.1378, -0.3889])\n",
      "Index - 4\n",
      "tensor([-1.2502])\n",
      "Index - 7\n",
      "tensor([0.0544])\n",
      "Index - 6\n",
      "tensor([-0.2071])\n",
      "Index - 9\n",
      "tensor([-0.3889])\n",
      "Index - 2\n",
      "tensor([-1.2054])\n",
      "Index - 0\n",
      "tensor([-2.0260])\n",
      "Index - 3\n",
      "tensor([-0.9122])\n",
      "Index - 5\n",
      "tensor([0.8032])\n",
      "Index - 1\n",
      "tensor([-2.0655])\n",
      "Index - 8\n",
      "tensor([0.1378])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print(f\"Index - {idx}\")\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "data = torch.randn(size=(10,))\n",
    "print(f\"Original data: {data}\")\n",
    "dataset = CustomDataset(data)\n",
    "loader = DataLoader(dataset=dataset, shuffle=True)\n",
    "\n",
    "for d in loader:\n",
    "    print(d)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `next(iter())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: tensor([-2.0260, -2.0655, -1.2054, -0.9122, -1.2502,  0.8032, -0.2071,  0.0544,\n",
      "         0.1378, -0.3889])\n",
      "Index - 4\n",
      "tensor([-1.2502])\n",
      "Index - 7\n",
      "tensor([0.0544])\n",
      "Index - 6\n",
      "tensor([-0.2071])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print(f\"Index - {idx}\")\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "data = torch.randn(size=(10,))\n",
    "print(f\"Original data: {data}\")\n",
    "dataset = CustomDataset(data)\n",
    "loader = DataLoader(dataset=dataset, shuffle=True)\n",
    "\n",
    "it = iter(loader)\n",
    "print(next(it))\n",
    "print(next(it))\n",
    "print(next(it))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterable Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work! infinite loop in `__iter__`, use `next(iter(loader))` to fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: tensor([-2.0260, -2.0655, -1.2054, -0.9122, -1.2502,  0.8032, -0.2071,  0.0544,\n",
      "         0.1378, -0.3889])\n",
      "tensor([[-1.2054]])\n",
      "tensor([[-2.0260]])\n",
      "tensor([[-1.2054]])\n",
      "tensor([[-2.0655]])\n",
      "tensor([[-0.2071]])\n",
      "tensor([[0.8032]])\n",
      "tensor([[-0.3889]])\n",
      "tensor([[-1.2502]])\n",
      "tensor([[0.8032]])\n",
      "tensor([[-0.3889]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "\n",
    "class CustomIterableDataset(IterableDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            index = torch.randint(0, len(self.data), size=(1,))\n",
    "            yield self.data[index]\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "data = torch.randn(size=(10,))\n",
    "print(f\"Original data: {data}\")\n",
    "dataset = CustomIterableDataset(data)\n",
    "loader = DataLoader(dataset=dataset)\n",
    "\n",
    "it = iter(loader)\n",
    "for _ in range(10):\n",
    "    print(next(it))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can also be reproduced by `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: tensor([-2.0260, -2.0655, -1.2054, -0.9122, -1.2502,  0.8032, -0.2071,  0.0544,\n",
      "         0.1378, -0.3889])\n",
      "tensor([[-1.2054]])\n",
      "tensor([[-2.0260]])\n",
      "tensor([[-1.2054]])\n",
      "tensor([[-2.0655]])\n",
      "tensor([[-0.2071]])\n",
      "tensor([[0.8032]])\n",
      "tensor([[-0.3889]])\n",
      "tensor([[-1.2502]])\n",
      "tensor([[0.8032]])\n",
      "tensor([[-0.3889]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = torch.randint(0, len(self.data), size=(1,))  # override the index\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "data = torch.randn(size=(10,))\n",
    "print(f\"Original data: {data}\")\n",
    "dataset = CustomDataset(data)\n",
    "loader = DataLoader(dataset=dataset)\n",
    "\n",
    "for d in loader:\n",
    "    print(d)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT WORK! single iterator in `__iter__`, use `next(iter(loader))` to fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: tensor([-2.0260, -2.0655, -1.2054, -0.9122, -1.2502,  0.8032, -0.2071,  0.0544,\n",
      "         0.1378, -0.3889])\n",
      "tensor([[-1.2054]])\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/private/home/qingfeiyou/random-thoughts/datasets.ipynb Cell 14\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvscode-remote/private/home/qingfeiyou/random-thoughts/datasets.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m it \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(loader)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvscode-remote/private/home/qingfeiyou/random-thoughts/datasets.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvscode-remote/private/home/qingfeiyou/random-thoughts/datasets.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39;49m(it))\n",
      "File \u001b[0;32m~/.conda/envs/peer/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/peer/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.conda/envs/peer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:37\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_last \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(possibly_batched_index)):\n\u001b[0;32m---> 37\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_iter)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Only the 1st data can be fetched!!!\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "\n",
    "class CustomIterableDataset(IterableDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __iter__(self):\n",
    "        index = torch.randint(0, len(self.data), size=(1,))\n",
    "        yield self.data[index]\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "data = torch.randn(size=(10,))\n",
    "print(f\"Original data: {data}\")\n",
    "dataset = CustomIterableDataset(data)\n",
    "loader = DataLoader(dataset=dataset)\n",
    "\n",
    "it = iter(loader)\n",
    "for _ in range(10):\n",
    "    print(next(it))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT WORK! infinite loop in `__iter__`, use `for-loop` to fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: tensor([-2.0260, -2.0655, -1.2054, -0.9122, -1.2502,  0.8032, -0.2071,  0.0544,\n",
      "         0.1378, -0.3889])\n",
      "<torch.utils.data.dataloader._InfiniteConstantSampler object at 0x7fe80453f3a0>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "\n",
    "class CustomIterableDataset(IterableDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            index = torch.randint(0, len(self.data), size=(1,))\n",
    "            yield self.data[index]\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "data = torch.randn(size=(10,))\n",
    "print(f\"Original data: {data}\")\n",
    "dataset = CustomIterableDataset(data)\n",
    "loader = DataLoader(dataset=dataset)\n",
    "\n",
    "print(loader.sampler)\n",
    "\n",
    "for d in loader:\n",
    "    # This will create an infinite loop!!!\n",
    "    print(d)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2241e891bdcb43d70b129352065e4a3e3c43dbe26992820aebe42833f1782192"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
